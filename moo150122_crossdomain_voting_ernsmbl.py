# -*- coding: utf-8 -*-
"""MOO150122_crossDomain_voting_ernsmbl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KwyQsyA7of4nFOVrGMgICvNgHyWSgfxK
"""

from google.colab import drive
drive.mount('/content/drive')

import math
import random
import matplotlib.pyplot as plt
#==============================================================
import pandas as pd
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
 
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn import preprocessing
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
import warnings
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
import os
import time
from sklearn.model_selection import StratifiedKFold
 
from keras.models import Sequential
from keras.layers import Dense
import numpy
import matplotlib.pyplot as plt
 
from sklearn.metrics import confusion_matrix 
import numpy as np
 
 
warnings.filterwarnings("ignore")

# funtion to calculate accuracy ,auc of MOO
def function1(solution1,len1):
        
        
        estimators = []
        
        
        if(len1==len(yval)):
            Res_data= pd.read_csv('valid_ACC.csv') 
            Res_data_auc=pd.read_csv('valid_Auc.csv') 
        
        if(len1==len(ytest)):
            Res_data= pd.read_csv('test_ACC.csv') 
            Res_data_auc=pd.read_csv('test_auc.csv') 
            
        
        x1 = Res_data.iloc[:, :].values 
        x3= Res_data_auc.iloc[:, :].values 
        
        
        new_y_pred=[0]*len1
        new_auc_pred=[0]*len1
        
        
        TrrimedClassifier_count=0
        
        weight_levelZero=[0]*len1
        weight_levelOne=[0]*len1
        
        #=================================================================================
        #if(solution1[0]=='1'):
        x2 = Res_data.iloc[0, :].values 
        x4 = Res_data_auc.iloc[0, :].values
        
        #type conversion 
        for j in range(0,len1):            
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[0]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[0]



        TrrimedClassifier_count=TrrimedClassifier_count+1  
        #================================================================================
        
        #if(solution1[1]=='1'):
        x2 = Res_data.iloc[1, :].values 
        x4 = Res_data_auc.iloc[1, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[1]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[1]

        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        #=============================================================================       
        
        #if(solution1[2]=='1'):
        x2 = Res_data.iloc[2, :].values 
        x4 = Res_data_auc.iloc[2, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[2]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[2]

        
        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        #===========================================================================
        
        #if(solution1[3]=='1'):
        x2 = Res_data.iloc[3, :].values 
        x4 = Res_data_auc.iloc[3, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[3]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[3]

        #print("svc polynomial ",solution1[3])
        TrrimedClassifier_count=TrrimedClassifier_count+1 
        
        #================================================================
        
        #if(solution1[4]=='1'):
        x2 = Res_data.iloc[4, :].values 
        x4 = Res_data_auc.iloc[4, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[4]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[4]

        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        #==============================================================================
        
        #if(solution1[5]=='1'):
        x2 = Res_data.iloc[5, :].values 
        x4 = Res_data_auc.iloc[5, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[5]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[5]

        #print("gaussian ",solution1[5])
        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        #==================================================================================
        """
        
        #if(solution1[6]=='1'):
        x2 = Res_data.iloc[6, :].values 
        x4 = Res_data_auc.iloc[6, :].values
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[6]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[6]

        #print("ANN ",solution1[6])
        TrrimedClassifier_count=TrrimedClassifier_count+1    
        
        #===========================================================================================
          
        #if(solution1[7]=='1'):
        x2 = Res_data.iloc[7, :].values 
        x4 = Res_data_auc.iloc[7, :].values
        
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[7]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[7]

        #print("ANN ",solution1[6])
        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        #===========================================================================================
        
        #if(solution1[7]=='1'):
        x2 = Res_data.iloc[8, :].values 
        x4 = Res_data_auc.iloc[8, :].values
        
        #type conversion 
        for j in range(0,len1):
            x2[j]=float(x2[j])
            x4[j]=float(x4[j])
          
        
        
        for i in range(0,len1):
            if (x2[i]==0):
                weight_levelZero[i]=weight_levelZero[i]+solution1[8]
            else:
                 weight_levelOne[i]=weight_levelZero[i]+solution1[8]

        TrrimedClassifier_count=TrrimedClassifier_count+1  
        
        """
        #print("TrrimedClassifier_count is", TrrimedClassifier_count)
        
        #if(solution1[0]=='1'or solution1[1]=='1'or solution1[2]=='1'or solution1[3]=='1'or solution1[4]=='1'or solution1[5]=='1'or solution1[6]=='1'):            
        for i in range(0,len1):
            if(weight_levelZero[i]>weight_levelOne[i]):
                new_y_pred[i]=0
            else:
                new_y_pred[i]=1    

        #print(" class o weignt ",weight_levelZero[i]," class 1 weight ",weight_levelOne[i]," assigned class ", new_y_pred[i])    
        
               
        for i in range(0,len1):
            count0=0.00000001
            count1=0.00000001
            if(new_y_pred[i]==0):
                for j in range(0,TrrimedClassifier_count):
                    if(x1[j][i]==0):
                        #print("x[i][j]=0 for i, j",i,j)
                        new_auc_pred[i]=new_auc_pred[i]+x3[j][i]
                        count0=count0+1
                #print("count0=",count0)
                new_auc_pred[i]=new_auc_pred[i]/count0       
            else:
                for j in range(0,TrrimedClassifier_count):
                    if(x1[j][i]==1):
                        #print("x[i][j]=1 for i, j",i,j)
                        new_auc_pred[i]=new_auc_pred[i]+x3[j][i]
                        count1=count1+1
                #print("count1=",count1)        
                new_auc_pred[i]=new_auc_pred[i]/count1           


        
        if(len1==len(yval)):            
            acc1=accuracy_score(yval, new_y_pred)                    
            auc1=roc_auc_score(yval, new_auc_pred)  
            #auc1=roc_auc_score(yval, new_y_pred)             
            print ("Accuracy : ", acc1,'\t',"auc","\t", auc1)  
                
        if(len1==len(ytest)):    
            acc1=accuracy_score(ytest, new_y_pred)
            auc1=roc_auc_score(ytest, new_auc_pred)
            print ("Accuracy : ", acc1,'\t',"auc","\t", auc1)  
                
 
        #os.remove('ensmbleIntermidiateTrimmed2.csv')
        #print("solution1",solution1)
        
        return(acc1,auc1)
            
 
        
    #return(0.00,0.00)

# all seperate function
 
def index_of(a,list):
    for i in range(0,len(list)):
        if list[i] == a:
            return i
    return -1
 
#Function to sort by values
def sort_by_values(list1, values):
    sorted_list = []
    while(len(sorted_list)!=len(list1)):
        if index_of(min(values),values) in list1:
            sorted_list.append(index_of(min(values),values))
        values[index_of(min(values),values)] = math.inf
    return sorted_list
 
#Function to carry out NSGA-II's fast non dominated sort
def fast_non_dominated_sort(values1, values2):
    
    S=[[] for i in range(0,len(values1))]
    front = [[]]
    n=[0 for i in range(0,len(values1))]
    rank = [0 for i in range(0, len(values1))]
 
    for p in range(0,len(values1)):
        S[p]=[]
        n[p]=0
        for q in range(0, len(values1)):
            if (values1[p] > values1[q] and values2[p] > values2[q]) or (values1[p] >= values1[q] and values2[p] > values2[q]) or (values1[p] > values1[q] and values2[p] >= values2[q]):
#           if (values1[p] < values1[q] and values2[p] < values2[q]) or (values1[p] <= values1[q] and values2[p] < values2[q]) or (values1[p] < values1[q] and values2[p] <= values2[q]):
                if q not in S[p]:
                    S[p].append(q)
            elif (values1[q] > values1[p] and values2[q] > values2[p]) or (values1[q] >= values1[p] and values2[q] > values2[p]) or (values1[q] > values1[p] and values2[q] >= values2[p]):
#           elif (values1[q] < values1[p] and values2[q] < values2[p]) or (values1[q] <= values1[p] and values2[q] < values2[p]) or (values1[q] < values1[p] and values2[q] <= values2[p]):    
                n[p] = n[p] + 1
        if n[p]==0:
            rank[p] = 0
            if p not in front[0]:
                front[0].append(p)
 
    i = 0
    while(front[i] != []):
        Q=[]
        for p in front[i]:
            for q in S[p]:
                n[q] =n[q] - 1
                if( n[q]==0):
                    rank[q]=i+1
                    if q not in Q:
                        Q.append(q)
        i = i+1
        front.append(Q)
 
    del front[len(front)-1]
    return front
 
#Function to calculate crowding distance
def crowding_distance(values1, values2, front):
    distance = [0 for i in range(0,len(front))]
    sorted1 = sort_by_values(front, values1[:])
    sorted2 = sort_by_values(front, values2[:])
    distance[0] = 4444444444444444
    distance[len(front) - 1] = 4444444444444444
    for k in range(1,len(front)-1):
        distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))
    for k in range(1,len(front)-1):
        distance[k] = distance[k]+ (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))
    return distance
 
#Function to carry out the crossover
def crossover(a,b):
    r_cross = 0.9 # crossover rate   
    rd=random.random()
    if rd < r_cross:
      cross_point =random.randint(1, Classifier_count-2)  
      off1=a[:cross_point]+b[cross_point:]
      off2=b[:cross_point]+a[cross_point:]     
    else:
      off1=a
      off2=b
    r=random.random()
    if r>0.5:        
        return mutation(off1)
    else:        
        return mutation(off2)
 
#Function to carry out the mutation operator
def mutation(solution):        
    #r_mut = 1.0 / float(Classifier_count) # mutation rate       
    r_mut=0.5
    mutation_prob = random.random()
    
    #if mutation_prob <1: #for continuous valued cromosome
        #solution=rand_key(Classifier_count)    
    
    
    if mutation_prob <r_mut: #for binary cromosome
        pos=random.randint(0, Classifier_count-1)
        if(solution[pos]=='0'):
            solution[pos]=='1'
        else:
          solution[pos]=='0'
        pos1=random.randint(0, Classifier_count-1)  
        if(pos1!=pos):
          if(solution[pos1]=='0'):
            solution[pos]=='1'
          else:
            solution[pos1]=='0'
        """
        pos1=pos+1
        if(solution[pos]=='0'):
            solution=solution[:pos]+'1'+solution[pos1:]
    
        if(solution[pos]=='1'):
            solution=solution[0:pos]+'0'+solution[pos1:]    
        """
    return solution
 
def rand_key(p):    
    key = [0]*p
    s=0
    k=0
    for i in range(p): 
        #temp = random.randint(1, 100)
        temp = random.randint(0, 1)
        #key[i]= temp/100
        key[i]= temp
        #s=s+temp
    """  
    for i in range(p):     
        key[i]=key[i]/s
        k=k+key[i]
    """
       
    return(key)

start_time = time.time()
 
file5=open('result2.csv', 'w+')
#warnings.filterwarnings("ignore")
 
#from sklearn.decomposition import PCA

#   /content/drive/MyDrive/colab data files/TEST WITH UNSEEN DATA/data746 ORDER.csv
#   /content/drive/MyDrive/colab data files/TEST WITH UNSEEN DATA/DATA1625 ORDER.csv
#  /content/drive/MyDrive/colab data files/TEST WITH UNSEEN DATA/Schlling Data Order.csv
# /content/drive/MyDrive/colab data files/TEST WITH UNSEEN DATA/impense order.csv

#trainSet = pd.read_csv('/content/drive/MyDrive/colab data files/746/746 octapeptide.csv',header=None)
#trainSet =pd.read_csv('/content/drive/MyDrive/colab data files/1625/1625 octapeptide.csv',header=None)
trainSet =pd.read_csv('/content/drive/MyDrive/colab data files/schlling/schlling octapeptide.csv',header=None)
#total_feature_oct=int(1)
X_train_octapep = trainSet.iloc[:, 0:1].values  
train_label= trainSet.iloc[:, 1].values 

testSet=pd.read_csv('/content/drive/MyDrive/colab data files/746/746 octapeptide.csv',header=None)
#testSet = pd.read_csv('/content/drive/MyDrive/colab data files/impense/impense data octapeptide.csv',header=None)
#testSet = pd.read_csv('/content/drive/MyDrive/colab data files/schlling/schlling octapeptide.csv',header=None)
#testSet = pd.read_csv('/content/drive/MyDrive/colab data files/1625/1625 octapeptide.csv',header=None)
#total_feature1=int(1)
X_test_octapep = testSet.iloc[:, 0:1].values  
test_label= testSet.iloc[:, 1].values 

#dataset = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_impense_240.csv')
#dataset = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_746_240.csv')
dataset = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_1625_240.csv')
#dataset=pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_schilling_240.csv')
#dataset=pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/746_152.csv',header=None)
#dataset = pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/1625_152.csv',header=None)
#dataset=pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/shiling_152.csv',header=None)
#dataset = pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/impense_152.csv',header=None)
#dataset = pd.read_csv('/content/drive/MyDrive/colab data files/seq+struc/1625_25_420_160_alp_beta_coli_asa_rsa_burried.csv')
#total_feature=int(653)
total_feature=int(152)
print("shape training",dataset.shape)
xtrain = dataset.iloc[:, 0:total_feature].values  
ytrain = dataset.iloc[:, total_feature].values 
 

#====================================test set====================================================

dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_impense_240.csv')
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_schilling_240.csv')
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_1625_240.csv')
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/240 feature set/new_appro_746_240.csv')
#dataset1=pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/746_152.csv',header=None)
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/1625_152.csv',header=None)
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/shiling_152.csv',header=None)
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/152 feature set/impense_152.csv',header=None)
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/seq+struc/746_25_420_160_alp_beta_coli_asa_rsa_burried.csv')
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/seq+struc/schling_25_420_160_alp_beta_coli_asa_rsa_burried.csv')
#dataset1 = pd.read_csv('/content/drive/MyDrive/colab data files/seq+struc/schling_25_420_160_alp_beta_coli_asa_rsa_burried.csv')
#p=dataset1.isnull().sum().sum()
#print("p==",p)
#total_feature=int(653)
total_feature=int(152)
xtest = dataset1.iloc[:, 0:total_feature].values  
ytest= dataset1.iloc[:, total_feature].values 
"""
scaler = StandardScaler()
xtrain=scaler.fit_transform(xtrain)
xtest = scaler.fit_transform(xtest)
"""
#xtrain=preprocessing.normalize(xtrain)
#xtest=preprocessing.normalize(xtest)
#================remove contradictory samples===========
"""
dropIndex_train=[]
dropIndex_test=[]

index_of_octapep_test=-1
for i in X_test_octapep :
  index_of_octapep_test+=1  
  if i in X_train_octapep:
    result = np.where(X_train_octapep[:,0] == i)
    train_index=result[0][0]
    test_index=index_of_octapep_test
    #if (train_label[train_index]==test_label[test_index]):
        #dropIndex_test.append( test_index)
    if (train_label[train_index]!=test_label[test_index]):  
        dropIndex_train.append( train_index)
        dropIndex_test.append( test_index)

xtrain = np.delete(xtrain,dropIndex_train, 0)
ytrain= np.delete(ytrain,dropIndex_train, 0)

xtest=np.delete(xtest,dropIndex_test, 0)
ytest=np.delete(ytest,dropIndex_test, 0)
"""

print("xtrain shape",xtrain.shape)
print("xtest shape",xtest.shape)

print("ytrain shape",ytrain.shape)
print("ytest shape",ytest.shape)


"""#xtest=preprocessing.normalize(xtest)
scaler = StandardScaler()
xtrain=scaler.fit_transform(xtrain)
xtest = scaler.fit_transform(xtest)
 
"""


l2,m2=xtest.shape
print("\n test shape ",xtest.shape)


#=============Resize train and test dataset===============================


 
#========================================
#=========================================
#===========================================
#xtrain, xvalid, ytrain, yvalid = train_test_split(x_ann, y, test_size = 0.10, random_state = 22,stratify=y) 

#no_of_fold=10
#k_fold_res_acc=0
#k_fold_res_auc=0
#fold=1

"""
for itr in range(0,l1):
    y[itr]=int(y[itr])

for itr in range(0,l2):
    ytest[itr]=int(ytest[itr])    

kf=StratifiedKFold(n_splits=no_of_fold, random_state=None, shuffle=True)
for train_index, test_index in kf.split(xtrain,y):
"""  
for itr in range(1,2):
    
    #print("TRAIN:", train_index, "\t","TEST:", test_index ,"\n")
    #xtrain, xval = x_ann[train_index], x_ann[test_index]
    #ytrain, yval = y[train_index], y[test_index]
    
    #xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain, test_size = 0.05, random_state = 42,stratify=ytrain) 
    #xtest, xval, ytest, yval = train_test_split(xtest,ytest, test_size = 0.30, random_state = 22,stratify=ytest)
    
    xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain, test_size = 0.05, random_state = 22,stratify=ytrain) 
   
    
    pop_size =150 #100 #150
    max_gen =20 #30
     
 
    len1=len(yval)
    len2=len(ytest)
    
    print("len1",len1)
    #print("\n fold no.===============",fold)
    file1=open('valid_ACC.csv', 'w+')    
    file3=open('valid_Auc.csv', 'w+')  
    
    file4=open('test_auc.csv', 'w+')
    file2=open('test_ACC.csv', 'w+')
             
    
  
    for i in range(0,len1):
        file1.write(str('k'))
        file1.write(',')
        file3.write(str('k'))
        file3.write(',')
    file1.write('\n') 
    file3.write('\n')
    
      
    
    for i in range(0,len2):
        file2.write(str('k'))
        file2.write(',')
        file4.write(str('k'))
        file4.write(',')
    file2.write('\n')  
    file4.write('\n')  
    # =============================================================================
    
    model1 = LogisticRegression(solver='lbfgs')
    model1 .fit(xtrain, ytrain) 
    #for ACC=========================================
    y_pred1 = model1 .predict(xval) 
    
    y_pred = model1 .predict(xtest) 
 
 
    #for AUC=========================================
    y_pred2=model1.decision_function(xval)
    
    y_pred22 = model1.decision_function(xtest)
    
 
 
    print(len(y_pred1))
    from sklearn.metrics import accuracy_score 
    
    print (" LogisticRegression Accuracy : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 

    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')
 
    
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
 
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')

    
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
 
 
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity : \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    # =============================================================================
    
    model2 =RandomForestClassifier(random_state=42, n_estimators=100)
    model2 .fit(xtrain, ytrain) 
    y_pred1 = model2 .predict(xval) 
  
    y_pred = model2 .predict(xtest) 
 
    
    y_pred2=model2.predict_proba(xval)[:, 1]

   
    y_pred22 = model2.predict_proba(xtest)[:, 1]
    
 
   
    print (" RandomForest Accuracy : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 
    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')

  
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
    
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')
 
  
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
    
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity : \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    #==============================================================================
  
    model3 = SVC(gamma='scale',kernel='sigmoid',probability=True)
    model3 .fit(xtrain, ytrain) 
 
    y_pred1 = model3 .predict(xval) 
    
    y_pred = model3 .predict(xtest) 
 
    
    y_pred2=model3.predict_proba(xval)[:, 1]
    y_pred22 = model3.predict_proba(xtest)[:, 1]
    
 
    
    print (" sigmoid kernel Accuracy : : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 
    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')
 
    
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
 
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')
 
    
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity: \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    # =============================================================================
    
    model4 = SVC(gamma='scale',kernel='poly', degree=2,probability=True)
    model4 .fit(xtrain, ytrain) 
 
    y_pred1 = model4 .predict(xval) 
   
    y_pred = model4 .predict(xtest) 
 
    
    y_pred2=model4.predict_proba(xval)[:, 1]
    
    y_pred22 = model4.predict_proba(xtest)[:, 1]
    
 
   
    print (" polynomial kernel Accuracy : : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 
    
    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')
 
    
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
 
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')
 
   
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity : \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    #===================================================================================
    
    model5 = SVC(kernel='linear',probability=True)
    model5 .fit(xtrain, ytrain) 
 
    y_pred1 = model5 .predict(xval) 
    
    y_pred = model5.predict(xtest) 
 
    
    y_pred2=model5.predict_proba(xval)[:, 1]
    
    y_pred22 = model5.predict_proba(xtest)[:, 1]
    
 
    
    print (" linear kernel Accuracy : : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 
 
    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')
 
   
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
 
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')
 
   
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity : \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    #====================================================================================
    
    model6 = SVC(gamma='scale',kernel='rbf',probability=True)
    model6 .fit(xtrain, ytrain) 
    
    y_pred1 = model6 .predict(xval) 
    
    y_pred = model6.predict(xtest) 
 
    
    y_pred2=model6.predict_proba(xval)[:, 1]
    
    y_pred22 = model6.predict_proba(xtest)[:, 1]
    
 
    
    print (" gaussian kernel Accuracy : : ", accuracy_score(ytest, y_pred),'\t',"auc","\t", roc_auc_score(ytest, y_pred22)) 
 
    for i in range(0,len1):
        file1.write(str(y_pred1[i]))
        file1.write(',')
    file1.write('\n')
 
    
    for i in range(0,len2):
        file2.write(str(y_pred[i]))
        file2.write(',')
    file2.write('\n')
 
    for i in range(0,len1):
        file3.write(str(y_pred2[i]))
        file3.write(',')
    file3.write('\n')
 
    
    for i in range(0,len2):
        file4.write(str(y_pred22[i]))
        file4.write(',')
    file4.write('\n')
    
    #cm = confusion_matrix(ytest, y_pred)       
    #print ("Sensitivity : \n", cm[0][0]/(cm[0][0]+cm[1][0])) 
    
    
    #=====================================================================
    file1.close()
    file2.close()
    file3.close()
    file4.close()
    Classifier_count=6
    
    #========================================
    #=========================================
    #===========================================
 
    solution=[rand_key(Classifier_count) for i in range(0,pop_size)]
    print(solution)
    gen_no=0
    function1_values=[0]*pop_size
    function2_values=[0]*pop_size
    
    
    
    while(gen_no<max_gen):
        print("generation number========================================================:",gen_no,"\n")
        #print("fold number========================================================:",fold,"\n")
              
        #for i in range(0,pop_size):
        #    print("solution",solution[i])
        #   function1(solution[i],len1)
        #print("POP_size",pop_size)
 
        function_values = [function1(solution[i],len1)for i in range(0,pop_size)]
        
        for loop in range(0,pop_size):
            function1_values[loop]=function_values[loop][0]
            function2_values[loop]=function_values[loop][1]
 
        
 
        non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])
 
        print(" non_dominated_sorted_solution " )
        print(non_dominated_sorted_solution)

    
 
       
 
        print("\n")
        crowding_distance_values=[]
        for i in range(0,len(non_dominated_sorted_solution)):
            crowding_distance_values.append(crowding_distance(function1_values[:],function2_values[:],non_dominated_sorted_solution[i][:]))
        solution2 = solution[:]
    
 
 
        while(len(solution2)!=2*pop_size):
            a1 = random.randint(0,pop_size-1)
            b1 = random.randint(0,pop_size-1)
            x=crossover(solution[a1],solution[b1])
            #print("==",x,"==")
            solution2.append(crossover(solution[a1],solution[b1]))
 
        
 
        new_pop_size=2*pop_size
 
        function1_values2=[0]*new_pop_size
        function2_values2=[0]*new_pop_size
 
        function_values2 = [function1(solution2[i],len1)for i in range(0,2*pop_size)]
 
        for loop in range(0,new_pop_size):
            function1_values2[loop]=function_values2[loop][0]
            function2_values2[loop]=function_values2[loop][1]
 
        
    #    function2_values2 = [function2(solution2[i])for i in range(0,2*pop_size)]
 
        non_dominated_sorted_solution2 = fast_non_dominated_sort(function1_values2[:],function2_values2[:])
 
        crowding_distance_values2=[]
        for i in range(0,len(non_dominated_sorted_solution2)):
            crowding_distance_values2.append(crowding_distance(function1_values2[:],function2_values2[:],non_dominated_sorted_solution2[i][:]))
        new_solution= []
        for i in range(0,len(non_dominated_sorted_solution2)):
            non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i] ) for j in range(0,len(non_dominated_sorted_solution2[i]))]
            front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])
            front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]
            front.reverse()
            for value in front:
                new_solution.append(value)
                if(len(new_solution)==pop_size):
                    break
            if (len(new_solution) == pop_size):
                break
             
        solution = [solution2[i] for i in new_solution]
        #print("solution for each generation", solution)
        
        gen_no = gen_no + 1
 
        
 
 
 
    print(function1_values)    
    print(function2_values)
    
    #print("best solution==^^^====^^^^========^^^^^ ======================================:", solution)
    print("best solution==^^^====^^^^========^^^^^ ====================================== using test result:")
    #for i in range(0,pop_size):
    #    function1(solution[i],len2)
  
    print("ultimate weight solution for each", solution)
    #function_values = [function1(solution[i],len2)for i in range(0,pop_size)]
 
    for i in range(0,pop_size):
        print(i,"\t",end="")
        function_values[i] = function1(solution[i],len2)
 
 
    #print("function1_values" )
    for loop in range(0,pop_size):
        function1_values[loop]=function_values[loop][0]
        function2_values[loop]=function_values[loop][1]
    
    non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])
    print(non_dominated_sorted_solution) 
    """
    index=non_dominated_sorted_solution[0]
    len3=len(index)
    #print(len3,index[0])
    #print(function1_values[index[0]])
    for s in range(0,len3):
        s1=function1_values[index[s]]
        s2=function2_values[index[s]]
        print("acc",s1," auc ",s2,"\n")
        #file5.write(str(s1))
        #file5.write(',')
        #file5.write(str(s2))
        #file5.write(',')
    #file5.write('\n')
    """
    index=non_dominated_sorted_solution[0]
    len3=len(index)
    #print(len3,index[0])
    #print(function1_values[index[0]])
    for s in range(0,len3):
            s1=function1_values[index[s]]
            s2=function2_values[index[s]]
            file5.write(str(s1))
            file5.write(',')
            file5.write(str(s2))
            file5.write(',')
    file5.write('\n')
    
    print(function1_values[index[0]],function2_values[index[0]])
    print(round(function1_values[index[0]],2))
    print(round(function2_values[index[0]],2))
    
    #Lets plot the final front now
    f1 = [i * 1 for i in function1_values]
    f2 = [j * 1 for j in function2_values]
    plt.xlabel('Accuracy', fontsize=15)
    plt.ylabel('Auc', fontsize=15)
    plt.scatter(f1, f2)
    plt.show()    
        
 
    os.remove('result2.csv')
    os.remove('test_ACC.csv')
    os.remove('test_auc.csv')
    os.remove('valid_ACC.csv')
    os.remove('valid_Auc.csv')
    
    

   
file5.close() 

#avg_acc=k_fold_res_acc/no_of_fold
#avg_auc=k_fold_res_auc/no_of_fold
#print("acc ",avg_acc,"\t auc  ",avg_auc)
  
print("--- %s seconds ---" % (time.time() - start_time))







